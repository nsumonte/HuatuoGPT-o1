# ğŸ¥ Medical Reasoning SFT - Entrenamiento de Modelos con Razonamiento Complejo

<div align="center">

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.5](https://img.shields.io/badge/PyTorch-2.5-ee4c2c.svg)](https://pytorch.org/)
[![DeepSpeed](https://img.shields.io/badge/DeepSpeed-0.15-green.svg)](https://www.deepspeed.ai/)
[![Weights & Biases](https://img.shields.io/badge/W%26B-Tracking-yellow.svg)](https://wandb.ai/)

</div>

## ğŸ“‹ DescripciÃ³n

Este repositorio contiene el cÃ³digo para entrenar modelos de lenguaje con **razonamiento mÃ©dico complejo** mediante Supervised Fine-Tuning (SFT). El modelo aprende a:

1. **Pensar paso a paso** antes de responder (Complex Chain-of-Thought)
2. **Razonar sobre problemas mÃ©dicos** de forma estructurada
3. **Generar respuestas precisas** basadas en el razonamiento previo

### Formato de Salida del Modelo

```
## Thinking
[Proceso de razonamiento paso a paso]

## Final Response
[Respuesta final basada en el razonamiento]
```

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
.
â”œâ”€â”€ SFT_stage1.py                    # ğŸ¯ Script principal de entrenamiento SFT
â”œâ”€â”€ RL_stage2.py                     # Script de Reinforcement Learning (PPO)
â”œâ”€â”€ test_dataset.py                  # Script de verificaciÃ³n del dataset
â”œâ”€â”€ merged_medical_datasets_v2.json  # Dataset de entrenamiento (espaÃ±ol)
â”œâ”€â”€ requirements.txt                 # Dependencias
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ deepspeed_zero2_local.yaml   # Config para pruebas locales (1 GPU)
â”‚   â”œâ”€â”€ deepspeed_zero3.yaml         # Config original Zero3
â”‚   â””â”€â”€ deepspeed_zero3_8gpu.yaml    # Config optimizada para 8 GPUs
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_local_test.sh            # Script de prueba local
â”‚   â””â”€â”€ run_8gpu_training.sh         # Script de entrenamiento producciÃ³n
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ demo_data.json               # Datos de demostraciÃ³n
â”‚   â””â”€â”€ test_sample.json             # Muestra para pruebas (generada)
â”‚
â””â”€â”€ evaluation/
    â”œâ”€â”€ eval.py                      # Script de evaluaciÃ³n
    â””â”€â”€ data/eval_data.json          # Datos de evaluaciÃ³n
```

---

## ğŸ“Š Estructura del Dataset

El dataset debe ser un archivo JSON con la siguiente estructura:

```json
[
  {
    "Pregunta": "La pregunta mÃ©dica a responder",
    "Razonamiento_Complejo": "El proceso de pensamiento paso a paso...",
    "Respuesta": "La respuesta final basada en el razonamiento",
    "Archivo_fuente": "Origen del dato (opcional)"
  }
]
```

### Campos Requeridos

| Campo | DescripciÃ³n |
|-------|-------------|
| `Pregunta` | La pregunta o problema mÃ©dico |
| `Razonamiento_Complejo` | Cadena de pensamiento detallada |
| `Respuesta` | Respuesta final concisa |

### Campos Opcionales

| Campo | DescripciÃ³n |
|-------|-------------|
| `Archivo_fuente` | Origen del dato para tracking |

---

## âš™ï¸ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone <tu-repositorio>
cd ict
```

### 2. Crear entorno virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
.\venv\Scripts\activate   # Windows
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar credenciales (opcional)

```bash
# WandB
wandb login

# HuggingFace
huggingface-cli login
```

---

## ğŸ§ª Pruebas del Dataset

Antes de entrenar, verifica que tu dataset estÃ© correcto:

```bash
# Verificar estructura
python test_dataset.py --data_path ./merged_medical_datasets_v2.json

# Verificar estructura + tokenizaciÃ³n
python test_dataset.py --data_path ./merged_medical_datasets_v2.json --test_tokenization

# Crear muestra pequeÃ±a para pruebas
python test_dataset.py --data_path ./merged_medical_datasets_v2.json --create_sample
```

---

## ğŸš€ Entrenamiento

### Prueba Local (1 GPU)

Para verificar que todo funciona antes de ejecutar en producciÃ³n:

```bash
# Dar permisos de ejecuciÃ³n
chmod +x scripts/run_local_test.sh

# Ejecutar prueba local
./scripts/run_local_test.sh
```

O manualmente:

```bash
accelerate launch \
    --config_file ./configs/deepspeed_zero2_local.yaml \
    --num_processes 1 \
    SFT_stage1.py \
    --model_path meta-llama/Llama-3.2-1B-Instruct \
    --data_path ./data/test_sample.json \
    --max_samples 10 \
    --max_seq_len 1024 \
    --train_bsz_per_gpu 1 \
    --n_epochs 1 \
    --experiment_name test_local
```

### Entrenamiento Completo (8 GPUs)

```bash
chmod +x scripts/run_8gpu_training.sh

# Entrenamiento bÃ¡sico
./scripts/run_8gpu_training.sh

# Con opciones personalizadas
./scripts/run_8gpu_training.sh \
    --model_path meta-llama/Llama-3.1-8B-Instruct \
    --experiment_name mi_experimento \
    --n_epochs 3 \
    --wandb_online
```

O manualmente:

```bash
accelerate launch \
    --config_file ./configs/deepspeed_zero3_8gpu.yaml \
    --num_processes 8 \
    --num_machines 1 \
    --machine_rank 0 \
    --deepspeed_multinode_launcher standard \
    SFT_stage1.py \
    --model_path meta-llama/Llama-3.1-8B-Instruct \
    --data_path ./merged_medical_datasets_v2.json \
    --max_seq_len 8192 \
    --train_bsz_per_gpu 2 \
    --gradient_accumulation_steps 8 \
    --n_epochs 3 \
    --learning_rate 5e-6 \
    --experiment_name medical_o1_spanish \
    --wandb_online
```

---

## ğŸ“ˆ Tracking con WandB

### Modo Offline (por defecto)

Los logs se guardan localmente en `./train_logs/` y pueden sincronizarse despuÃ©s:

```bash
wandb sync ./train_logs/<experiment_name>/
```

### Modo Online

Agrega `--wandb_online` al comando de entrenamiento:

```bash
accelerate launch ... SFT_stage1.py ... --wandb_online
```

### MÃ©tricas Trackeadas

| MÃ©trica | DescripciÃ³n |
|---------|-------------|
| `loss` | Loss de entrenamiento |
| `acc` | Accuracy en tokens predichos |
| `lr` | Learning rate actual |
| `skip` | Steps saltados por overflow |

---

## ğŸ¤— IntegraciÃ³n con HuggingFace Hub

### Subir Checkpoints AutomÃ¡ticamente

```bash
accelerate launch ... SFT_stage1.py \
    --hf_token YOUR_TOKEN \
    --push_to_hub \
    --hf_repo_id tu-usuario/nombre-modelo
```

### Subir Manualmente

```python
from huggingface_hub import HfApi

api = HfApi()
api.upload_folder(
    folder_path="./ckpts/experiment_name/checkpoint-X-Y/tfmr",
    repo_id="tu-usuario/nombre-modelo",
    commit_message="Upload trained model"
)
```

---

## ğŸ“ Argumentos de Entrenamiento

### Modelo y Datos

| Argumento | Default | DescripciÃ³n |
|-----------|---------|-------------|
| `--model_path` | **requerido** | Ruta al modelo base (local o HuggingFace) |
| `--data_path` | **requerido** | Ruta al dataset JSON |
| `--max_samples` | 0 | Limitar ejemplos (0 = sin lÃ­mite) |

### Entrenamiento

| Argumento | Default | DescripciÃ³n |
|-----------|---------|-------------|
| `--max_seq_len` | 8192 | Longitud mÃ¡xima de secuencia |
| `--train_bsz_per_gpu` | 2 | Batch size por GPU |
| `--gradient_accumulation_steps` | 8 | Steps de acumulaciÃ³n |
| `--n_epochs` | 3 | NÃºmero de epochs |
| `--learning_rate` | 5e-6 | Learning rate |
| `--warmup_rates` | 0.05 | Ratio de warmup |
| `--weight_decay` | 0.1 | Weight decay |

### Outputs

| Argumento | Default | DescripciÃ³n |
|-----------|---------|-------------|
| `--output_dir` | ./ckpts | Directorio de checkpoints |
| `--log_dir` | ./train_logs | Directorio de logs |
| `--max_ckpts` | 2 | MÃ¡ximo checkpoints a mantener |
| `--experiment_name` | medical_sft_spanish | Nombre del experimento |

### WandB y HuggingFace

| Argumento | Default | DescripciÃ³n |
|-----------|---------|-------------|
| `--wandb_online` | False | Usar WandB en modo online |
| `--hf_token` | None | Token de HuggingFace |
| `--push_to_hub` | False | Subir checkpoints a HF Hub |
| `--hf_repo_id` | None | ID del repo en HuggingFace |

---

## ğŸ§  Arquitectura del CÃ³digo

### `SFT_stage1.py`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SFT_stage1.py                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Train_dataset                                              â”‚
â”‚  â”œâ”€â”€ __init__: Carga JSON, valida campos                   â”‚
â”‚  â”œâ”€â”€ get_response: Formatea Thinking + Response            â”‚
â”‚  â”œâ”€â”€ get_prompt: Crea input_ids y labels con mÃ¡scaras      â”‚
â”‚  â””â”€â”€ collate_fn: Padding dinÃ¡mico y batching               â”‚
â”‚                                                             â”‚
â”‚  SFTMetric                                                  â”‚
â”‚  â”œâ”€â”€ update: Acumula mÃ©tricas por step                     â”‚
â”‚  â””â”€â”€ get_metric: Reduce mÃ©tricas entre GPUs                â”‚
â”‚                                                             â”‚
â”‚  train()                                                    â”‚
â”‚  â”œâ”€â”€ Inicializa Accelerator + DeepSpeed                    â”‚
â”‚  â”œâ”€â”€ Configura WandB + HuggingFace                         â”‚
â”‚  â”œâ”€â”€ Carga modelo + tokenizer                              â”‚
â”‚  â”œâ”€â”€ Configura optimizer (AdamW) + scheduler (cosine)      â”‚
â”‚  â”œâ”€â”€ Loop de entrenamiento con gradient checkpointing      â”‚
â”‚  â””â”€â”€ save_checkpoint: Guarda modelo + sube a HF Hub        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

```
Dataset JSON
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pregunta   â”‚â”€â”€â”€â–¶â”‚ Chat Template â”‚â”€â”€â”€â–¶â”‚  input_ids  â”‚
â”‚             â”‚    â”‚   (Jinja2)    â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚ Razonamientoâ”‚â”€â”€â”€â–¶â”‚ ## Thinking  â”‚           â”‚
â”‚  + Respuestaâ”‚    â”‚ ## Response  â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                          â”‚                   â”‚
                          â–¼                   â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Labels = [-100] * len(query)â”‚
                   â”‚           + response_ids     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚    Model Forward Pass        â”‚
                   â”‚    CrossEntropyLoss          â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ Tips y Recomendaciones

### OptimizaciÃ³n de Memoria

1. **Reducir `max_seq_len`** si hay OOM (Out of Memory)
2. **Aumentar `gradient_accumulation_steps`** para mantener batch size efectivo
3. **Usar Zero3** para modelos grandes (>7B parÃ¡metros)
4. **Activar CPU offload** en la config de DeepSpeed si es necesario

### Velocidad de Entrenamiento

1. **Zero2 es mÃ¡s rÃ¡pido** que Zero3 para modelos que caben en memoria
2. **Desactivar CPU offload** si tienes suficiente VRAM
3. **Usar flash-attention** si estÃ¡ disponible

### Estabilidad

1. **Warmup del 5-10%** de los steps totales
2. **Learning rate bajo** (1e-6 a 5e-5) para fine-tuning
3. **Gradient clipping** viene habilitado por defecto en DeepSpeed

---

## ğŸ› Troubleshooting

### "CUDA out of memory"

```bash
# Reducir batch size
--train_bsz_per_gpu 1

# Reducir longitud de secuencia
--max_seq_len 4096

# Aumentar gradient accumulation
--gradient_accumulation_steps 16
```

### "Tokenizer has no chat_template"

El cÃ³digo asigna automÃ¡ticamente el template de LLaMA 3 si el modelo no tiene uno.

### WandB no sincroniza

```bash
# Sincronizar manualmente
wandb sync ./train_logs/<experiment_name>/wandb/

# O forzar modo online
--wandb_online
```

---

## ğŸ“š Referencias

- [HuatuoGPT-o1 Paper](https://arxiv.org/pdf/2412.18925)
- [DeepSpeed Documentation](https://www.deepspeed.ai/)
- [Accelerate Documentation](https://huggingface.co/docs/accelerate)
- [TRL Library](https://github.com/huggingface/trl)

---

## ğŸ“„ Licencia

Este cÃ³digo estÃ¡ basado en el repositorio [HuatuoGPT-o1](https://github.com/FreedomIntelligence/HuatuoGPT-o1) y adaptado para datasets en espaÃ±ol con estructura personalizada.

---

<div align="center">

**Â¡Feliz entrenamiento! ğŸš€**

</div>
